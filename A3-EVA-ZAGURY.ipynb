{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81331132",
   "metadata": {
    "papermill": {
     "duration": 0.016222,
     "end_time": "2021-11-23T22:09:59.569943",
     "exception": false,
     "start_time": "2021-11-23T22:09:59.553721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Notebook example using Kaggle GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f5e436",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-23T22:09:59.609169Z",
     "iopub.status.busy": "2021-11-23T22:09:59.606010Z",
     "iopub.status.idle": "2021-11-23T22:10:01.264586Z",
     "shell.execute_reply": "2021-11-23T22:10:01.263929Z",
     "shell.execute_reply.started": "2021-11-23T21:15:05.667895Z"
    },
    "papermill": {
     "duration": 1.679751,
     "end_time": "2021-11-23T22:10:01.264747",
     "exception": false,
     "start_time": "2021-11-23T22:09:59.584996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "\n",
    "import shutil, sys  \n",
    "from tqdm import tqdm\n",
    "import PIL.Image as Image\n",
    "\n",
    "\n",
    "if not os.path.isdir('./experiments'):\n",
    "    os.makedirs('./experiments')\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4aa5fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:10:01.299326Z",
     "iopub.status.busy": "2021-11-23T22:10:01.298801Z",
     "iopub.status.idle": "2021-11-23T22:10:01.310442Z",
     "shell.execute_reply": "2021-11-23T22:10:01.309858Z",
     "shell.execute_reply.started": "2021-11-23T21:15:07.322247Z"
    },
    "papermill": {
     "duration": 0.032033,
     "end_time": "2021-11-23T22:10:01.310585",
     "exception": false,
     "start_time": "2021-11-23T22:10:01.278552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 16\n",
    "size=(299,299)\n",
    "interpolation = Image.BICUBIC\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'detect' : transforms.ToTensor(),\n",
    "\n",
    "    'train' : transforms.Compose([\n",
    "    #Data augmentation\n",
    "    transforms.Resize(size, interpolation=interpolation),  \n",
    "    #transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "\n",
    "    # Without data augmentation for validation\n",
    "    'val': transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b08f4",
   "metadata": {
    "papermill": {
     "duration": 0.013593,
     "end_time": "2021-11-23T22:10:01.339044",
     "exception": false,
     "start_time": "2021-11-23T22:10:01.325451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bird detection and Image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc269d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:10:01.386997Z",
     "iopub.status.busy": "2021-11-23T22:10:01.382254Z",
     "iopub.status.idle": "2021-11-23T22:10:01.395905Z",
     "shell.execute_reply": "2021-11-23T22:10:01.395453Z",
     "shell.execute_reply.started": "2021-11-23T21:15:07.334721Z"
    },
    "papermill": {
     "duration": 0.042111,
     "end_time": "2021-11-23T22:10:01.396010",
     "exception": false,
     "start_time": "2021-11-23T22:10:01.353899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect(path):\n",
    "    \"\"\"Detects birds in the dataset then crops the images\n",
    "    \"\"\"\n",
    "    maskrcnn = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    if torch.cuda.is_available():\n",
    "        maskrcnn.cuda()\n",
    "    maskrcnn.eval()\n",
    "    print(\"Detector loaded !\\n\")\n",
    "\n",
    "    print(\"Detecting birds ...\\n\")\n",
    "    \n",
    "    def sort_images(loader, folder, mapping):\n",
    "        name = 0\n",
    "        for data, target in tqdm(loader, leave=True, position=0):\n",
    "            results = maskrcnn(data.cuda())\n",
    "            for e, result in enumerate(results):\n",
    "                boxes = result['boxes'].tolist()    # Bounding boxes\n",
    "                labels =  result['labels'].tolist() # Labels\n",
    "                scores = result['scores'].tolist()  # Probability associated with bounding box\n",
    "\n",
    "                # Keep only bird labels and boxes (label 16 in COCO)\n",
    "                only_bird_boxes = np.array([boxes[i] for i in range(len(boxes)) if labels[i] == 16])\n",
    "                only_birds_scores= np.array([scores[i] for i in range(len(boxes))  if labels[i] == 16])\n",
    "                \n",
    "                # if low confidence -> hard image\n",
    "                if only_bird_boxes.size == 0 or only_birds_scores.max() < 0.85:   \n",
    "                    pass\n",
    "                else : \n",
    "                    try:\n",
    "                        i = np.argmax(only_birds_scores)\n",
    "                        box = only_bird_boxes[i]\n",
    "\n",
    "                        a, b, c, d = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "\n",
    "                        # Crop image on bird\n",
    "                        cropped = data[e, :, b:d, a:c]\n",
    "                        save_image(cropped, folder +\"/\"+mapping[target[e].item()]+\"/\"+str(name) +\".png\", format =\"png\")\n",
    "                    except ValueError:\n",
    "                        # Bounding box outside image (very rare)\n",
    "                        pass\n",
    "            name += 1\n",
    "\n",
    "    train_dataset = ImageFolder(path + '/train_images',\n",
    "                                        transform=data_transforms['detect'])\n",
    "                                  \n",
    "    class_to_id = train_dataset.class_to_idx \n",
    "    id_to_class = {v: k for k, v in class_to_id.items()}  # la classe ImageFolder assigne automatiquement un label pour chaque nom de classe (class -> idx)\n",
    "    \n",
    "    preprocess_train_loader = DataLoader(train_dataset,batch_size=1, \n",
    "                                         num_workers=1, shuffle=True)\n",
    "            \n",
    "    preprocess_val_loader = DataLoader(\n",
    "        datasets.ImageFolder(path + '/val_images',\n",
    "                             transform=data_transforms['detect']), batch_size=1,  \n",
    "                             num_workers=1)\n",
    "\n",
    "    sort_images(preprocess_train_loader, path + \"/train_images\", id_to_class)\n",
    "    sort_images(preprocess_val_loader, path + \"/val_images\", id_to_class)\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "def detect_test(path):\n",
    "    maskrcnn = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    if torch.cuda.is_available():\n",
    "        maskrcnn.cuda()\n",
    "    maskrcnn.eval()\n",
    "    print(\"Detector loaded !\\n\")\n",
    "\n",
    "    for f in tqdm(os.listdir(path +'/test_images/mistery_category')):\n",
    "        if 'jpg' in f:\n",
    "            data = data_transforms['detect'](pil_loader(path +'/test_images/mistery_category/' + f))\n",
    "            data = data.view(1, data.size(0), data.size(1), data.size(2)).cuda() \n",
    "            \n",
    "            results = maskrcnn(data.cuda())\n",
    "\n",
    "            for e, result in enumerate(results):\n",
    "                boxes = result['boxes'].tolist()    # Bounding boxes\n",
    "                labels =  result['labels'].tolist() # Labels\n",
    "                scores = result['scores'].tolist()  # Confidence associated with bounding box\n",
    "\n",
    "                # Keep only bird labels and boxes (label 16 in COCO)\n",
    "                only_bird_boxes = np.array([boxes[i] for i in range(len(boxes)) if labels[i] == 16])\n",
    "                only_birds_scores= np.array([scores[i] for i in range(len(boxes))  if labels[i] == 16])\n",
    "                \n",
    "                # if low confidence -> hard image\n",
    "                if only_bird_boxes.size == 0 or only_birds_scores.max() < 0.85:   \n",
    "                    shutil.copy(path +'/test_images/mistery_category/'+f, path+'/test_images/hard_test_images')\n",
    "                else : \n",
    "                    try:\n",
    "                        i = np.argmax(only_birds_scores)\n",
    "                        box = only_bird_boxes[i]\n",
    "\n",
    "                        a, b, c, d = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "\n",
    "                        # Crop image on bird\n",
    "                        cropped = data[e, :, b:d, a:c]\n",
    "\n",
    "                        shutil.copy(path +'/test_images/mistery_category/'+f, path+'/test_images/easy_test_images')\n",
    "                    except ValueError:\n",
    "                        # Bounding box outside image (very rare)\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a8fc3",
   "metadata": {
    "papermill": {
     "duration": 0.014072,
     "end_time": "2021-11-23T22:10:01.423736",
     "exception": false,
     "start_time": "2021-11-23T22:10:01.409664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since we do not have permission to modify the 'input data' (data provided by the competition administrators), we copy it into our working directory :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b605bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:10:01.457703Z",
     "iopub.status.busy": "2021-11-23T22:10:01.457052Z",
     "iopub.status.idle": "2021-11-23T22:10:11.758338Z",
     "shell.execute_reply": "2021-11-23T22:10:11.757486Z",
     "shell.execute_reply.started": "2021-11-23T21:15:07.361786Z"
    },
    "papermill": {
     "duration": 10.321244,
     "end_time": "2021-11-23T22:10:11.758555",
     "exception": false,
     "start_time": "2021-11-23T22:10:01.437311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/mva-recvis-2021/bird_dataset/train_images ./\n",
    "!cp -r ../input/mva-recvis-2021/bird_dataset/val_images ./\n",
    "!cp -r ../input/mva-recvis-2021/bird_dataset/test_images ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "928d099c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:10:11.793626Z",
     "iopub.status.busy": "2021-11-23T22:10:11.792803Z",
     "iopub.status.idle": "2021-11-23T22:13:19.842372Z",
     "shell.execute_reply": "2021-11-23T22:13:19.842827Z",
     "shell.execute_reply.started": "2021-11-23T21:15:16.110107Z"
    },
    "papermill": {
     "duration": 188.069679,
     "end_time": "2021-11-23T22:13:19.842988",
     "exception": false,
     "start_time": "2021-11-23T22:10:11.773309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc00e54e6e24c369f3f5f58f9b803b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/170M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector loaded !\n",
      "\n",
      "Detecting birds ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1082/1082 [01:57<00:00,  9.25it/s]\n",
      "100%|██████████| 103/103 [00:10<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector loaded !\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [00:43<00:00, 11.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#Adding images cropped on birds into our dataset\n",
    "detect('./.')\n",
    "detect_test('./.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88f258",
   "metadata": {
    "papermill": {
     "duration": 0.26738,
     "end_time": "2021-11-23T22:13:20.372781",
     "exception": false,
     "start_time": "2021-11-23T22:13:20.105401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f3d1cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:13:21.170903Z",
     "iopub.status.busy": "2021-11-23T22:13:21.170301Z",
     "iopub.status.idle": "2021-11-23T22:13:21.191777Z",
     "shell.execute_reply": "2021-11-23T22:13:21.191289Z",
     "shell.execute_reply.started": "2021-11-23T21:18:21.463956Z"
    },
    "papermill": {
     "duration": 0.33402,
     "end_time": "2021-11-23T22:13:21.191894",
     "exception": false,
     "start_time": "2021-11-23T22:13:20.857874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder('./train_images',transform=data_transforms['train']),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder('./val_images',transform=data_transforms['val']),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder('./test_images',transform=data_transforms['val']),\n",
    "    batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e2e6d",
   "metadata": {
    "papermill": {
     "duration": 0.26061,
     "end_time": "2021-11-23T22:13:21.714091",
     "exception": false,
     "start_time": "2021-11-23T22:13:21.453481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define and tune model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb4eac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:13:22.254942Z",
     "iopub.status.busy": "2021-11-23T22:13:22.254033Z",
     "iopub.status.idle": "2021-11-23T22:13:22.255818Z",
     "shell.execute_reply": "2021-11-23T22:13:22.256313Z",
     "shell.execute_reply.started": "2021-11-23T21:18:21.508416Z"
    },
    "papermill": {
     "duration": 0.280933,
     "end_time": "2021-11-23T22:13:22.256473",
     "exception": false,
     "start_time": "2021-11-23T22:13:21.975540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\"Function to set which layers are being frozen\n",
    "    \"\"\"\n",
    "    if feature_extracting: \n",
    "        #We do feature extracting\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False #freeze\n",
    "    else :\n",
    "        #We do finetunig (but we still freeze some layers)\n",
    "        for name, module in model.named_children():\n",
    "            if name not in ['layer3','layer4','fc']:\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = False  #freeze\n",
    "    \n",
    "            \n",
    "#Initialize and Reshape the Networks\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnext\":\n",
    "        \"\"\"resnext101_32x8d\n",
    "        \"\"\"\n",
    "        model_ft = torchvision.models.resnext101_32x8d(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet169\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet169(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f209ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:13:22.786387Z",
     "iopub.status.busy": "2021-11-23T22:13:22.785491Z",
     "iopub.status.idle": "2021-11-23T22:13:47.741699Z",
     "shell.execute_reply": "2021-11-23T22:13:47.740729Z",
     "shell.execute_reply.started": "2021-11-23T21:18:21.541008Z"
    },
    "papermill": {
     "duration": 25.22579,
     "end_time": "2021-11-23T22:13:47.741843",
     "exception": false,
     "start_time": "2021-11-23T22:13:22.516053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-8ba56ff5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6005ac554e5e49faac1476799f094f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/340M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = 20\n",
    "feature_extract = False\n",
    "\n",
    "# Initialize the model for this run\n",
    "model, input_size = initialize_model(\"resnext\",num_classes, feature_extract , use_pretrained=True)\n",
    "\n",
    "# Send the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb63ffdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:13:48.282239Z",
     "iopub.status.busy": "2021-11-23T22:13:48.281341Z",
     "iopub.status.idle": "2021-11-23T22:13:48.283067Z",
     "shell.execute_reply": "2021-11-23T22:13:48.283590Z",
     "shell.execute_reply.started": "2021-11-23T21:18:38.980705Z"
    },
    "papermill": {
     "duration": 0.276613,
     "end_time": "2021-11-23T22:13:48.283724",
     "exception": false,
     "start_time": "2021-11-23T22:13:48.007111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = []\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad == True :\n",
    "        params_to_update.append(param)      \n",
    "    \n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(params_to_update, lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091990c",
   "metadata": {
    "papermill": {
     "duration": 0.279296,
     "end_time": "2021-11-23T22:13:48.835978",
     "exception": false,
     "start_time": "2021-11-23T22:13:48.556682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947154c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:13:49.676160Z",
     "iopub.status.busy": "2021-11-23T22:13:49.675336Z",
     "iopub.status.idle": "2021-11-23T22:13:49.678710Z",
     "shell.execute_reply": "2021-11-23T22:13:49.679271Z",
     "shell.execute_reply.started": "2021-11-23T21:18:38.990498Z"
    },
    "papermill": {
     "duration": 0.445194,
     "end_time": "2021-11-23T22:13:49.679470",
     "exception": false,
     "start_time": "2021-11-23T22:13:49.234276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #forward\n",
    "        preds = model(data)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 25 == 0:\n",
    "            print('[{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "\n",
    "def validation(model):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            preds = model(data)\n",
    "            # sum up batch loss\n",
    "            validation_loss += criterion(preds, labels).data.item()\n",
    "            m = nn.Softmax(dim=1)\n",
    "            probs = m(preds)\n",
    "            preds_classes = probs.max(1, keepdim=True)[1]\n",
    "            correct += preds_classes.eq(labels.data.view_as(preds_classes)).sum()\n",
    "        validation_loss /= len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3baece82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:13:50.405737Z",
     "iopub.status.busy": "2021-11-23T22:13:50.399552Z",
     "iopub.status.idle": "2021-11-23T22:36:43.685852Z",
     "shell.execute_reply": "2021-11-23T22:36:43.686505Z",
     "shell.execute_reply.started": "2021-11-23T21:18:39.007478Z"
    },
    "papermill": {
     "duration": 1373.578434,
     "end_time": "2021-11-23T22:36:43.686717",
     "exception": false,
     "start_time": "2021-11-23T22:13:50.108283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################# EPOCH 1\n",
      "[0/2140 (0%)]\tLoss: 3.004722\n",
      "[800/2140 (37%)]\tLoss: 2.517818\n",
      "[1600/2140 (75%)]\tLoss: 2.108299\n",
      "\n",
      "Validation set: Average loss: 0.0535, Accuracy: 149/204 (73%)\n",
      "################################################# EPOCH 2\n",
      "[0/2140 (0%)]\tLoss: 1.286094\n",
      "[800/2140 (37%)]\tLoss: 0.767837\n",
      "[1600/2140 (75%)]\tLoss: 0.686665\n",
      "\n",
      "Validation set: Average loss: 0.0246, Accuracy: 178/204 (87%)\n",
      "################################################# EPOCH 3\n",
      "[0/2140 (0%)]\tLoss: 0.433558\n",
      "[800/2140 (37%)]\tLoss: 0.424929\n",
      "[1600/2140 (75%)]\tLoss: 0.277329\n",
      "\n",
      "Validation set: Average loss: 0.0183, Accuracy: 181/204 (89%)\n",
      "################################################# EPOCH 4\n",
      "[0/2140 (0%)]\tLoss: 0.336169\n",
      "[800/2140 (37%)]\tLoss: 0.284345\n",
      "[1600/2140 (75%)]\tLoss: 0.179312\n",
      "\n",
      "Validation set: Average loss: 0.0142, Accuracy: 185/204 (91%)\n",
      "################################################# EPOCH 5\n",
      "[0/2140 (0%)]\tLoss: 0.219844\n",
      "[800/2140 (37%)]\tLoss: 0.150907\n",
      "[1600/2140 (75%)]\tLoss: 0.228240\n",
      "\n",
      "Validation set: Average loss: 0.0133, Accuracy: 185/204 (91%)\n",
      "################################################# EPOCH 6\n",
      "[0/2140 (0%)]\tLoss: 0.243334\n",
      "[800/2140 (37%)]\tLoss: 0.159402\n",
      "[1600/2140 (75%)]\tLoss: 0.119694\n",
      "\n",
      "Validation set: Average loss: 0.0123, Accuracy: 187/204 (92%)\n",
      "################################################# EPOCH 7\n",
      "[0/2140 (0%)]\tLoss: 0.081699\n",
      "[800/2140 (37%)]\tLoss: 0.099868\n",
      "[1600/2140 (75%)]\tLoss: 0.136108\n",
      "\n",
      "Validation set: Average loss: 0.0130, Accuracy: 186/204 (91%)\n",
      "################################################# EPOCH 8\n",
      "[0/2140 (0%)]\tLoss: 0.132723\n",
      "[800/2140 (37%)]\tLoss: 0.062070\n",
      "[1600/2140 (75%)]\tLoss: 0.103719\n",
      "\n",
      "Validation set: Average loss: 0.0116, Accuracy: 184/204 (90%)\n",
      "################################################# EPOCH 9\n",
      "[0/2140 (0%)]\tLoss: 0.099860\n",
      "[800/2140 (37%)]\tLoss: 0.110531\n",
      "[1600/2140 (75%)]\tLoss: 0.056284\n",
      "\n",
      "Validation set: Average loss: 0.0116, Accuracy: 186/204 (91%)\n",
      "################################################# EPOCH 10\n",
      "[0/2140 (0%)]\tLoss: 0.067938\n",
      "[800/2140 (37%)]\tLoss: 0.024554\n",
      "[1600/2140 (75%)]\tLoss: 0.041720\n",
      "\n",
      "Validation set: Average loss: 0.0107, Accuracy: 187/204 (92%)\n",
      "################################################# EPOCH 11\n",
      "[0/2140 (0%)]\tLoss: 0.027497\n",
      "[800/2140 (37%)]\tLoss: 0.049465\n",
      "[1600/2140 (75%)]\tLoss: 0.041935\n",
      "\n",
      "Validation set: Average loss: 0.0108, Accuracy: 186/204 (91%)\n",
      "################################################# EPOCH 12\n",
      "[0/2140 (0%)]\tLoss: 0.041960\n",
      "[800/2140 (37%)]\tLoss: 0.028688\n",
      "[1600/2140 (75%)]\tLoss: 0.026855\n",
      "\n",
      "Validation set: Average loss: 0.0110, Accuracy: 186/204 (91%)\n",
      "################################################# EPOCH 13\n",
      "[0/2140 (0%)]\tLoss: 0.018151\n",
      "[800/2140 (37%)]\tLoss: 0.012984\n",
      "[1600/2140 (75%)]\tLoss: 0.008605\n",
      "\n",
      "Validation set: Average loss: 0.0107, Accuracy: 187/204 (92%)\n",
      "################################################# EPOCH 14\n",
      "[0/2140 (0%)]\tLoss: 0.019902\n",
      "[800/2140 (37%)]\tLoss: 0.037158\n",
      "[1600/2140 (75%)]\tLoss: 0.026071\n",
      "\n",
      "Validation set: Average loss: 0.0100, Accuracy: 187/204 (92%)\n",
      "################################################# EPOCH 15\n",
      "[0/2140 (0%)]\tLoss: 0.011464\n",
      "[800/2140 (37%)]\tLoss: 0.033071\n",
      "[1600/2140 (75%)]\tLoss: 0.009063\n",
      "\n",
      "Validation set: Average loss: 0.0116, Accuracy: 187/204 (92%)\n",
      "################################################# EPOCH 16\n",
      "[0/2140 (0%)]\tLoss: 0.008053\n",
      "[800/2140 (37%)]\tLoss: 0.017539\n",
      "[1600/2140 (75%)]\tLoss: 0.011110\n",
      "\n",
      "Validation set: Average loss: 0.0105, Accuracy: 186/204 (91%)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    print(\"################################################# EPOCH\", epoch)\n",
    "    train(model, epoch) \n",
    "    preds = validation(model)\n",
    "    model_file = 'experiments' + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85575749",
   "metadata": {
    "papermill": {
     "duration": 0.288572,
     "end_time": "2021-11-23T22:36:44.267391",
     "exception": false,
     "start_time": "2021-11-23T22:36:43.978819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60fde542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:36:44.846686Z",
     "iopub.status.busy": "2021-11-23T22:36:44.845769Z",
     "iopub.status.idle": "2021-11-23T22:37:18.296167Z",
     "shell.execute_reply": "2021-11-23T22:37:18.296827Z",
     "shell.execute_reply.started": "2021-11-23T21:41:31.725490Z"
    },
    "papermill": {
     "duration": 33.745813,
     "end_time": "2021-11-23T22:37:18.297022",
     "exception": false,
     "start_time": "2021-11-23T22:36:44.551209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "517it [00:33, 15.47it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = np.array([])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (data, labels) in tqdm(enumerate(test_loader, 0)):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        output1 = model(data)\n",
    "        sm = nn.Softmax(dim=1)(output1)\n",
    "        pred = sm.max(1, keepdim=True)[1]    \n",
    "        preds = np.hstack((preds, torch.squeeze(pred).cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3366c512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-23T22:37:19.400147Z",
     "iopub.status.busy": "2021-11-23T22:37:19.399347Z",
     "iopub.status.idle": "2021-11-23T22:37:19.403318Z",
     "shell.execute_reply": "2021-11-23T22:37:19.403905Z",
     "shell.execute_reply.started": "2021-11-23T21:42:05.370590Z"
    },
    "papermill": {
     "duration": 0.600491,
     "end_time": "2021-11-23T22:37:19.404102",
     "exception": false,
     "start_time": "2021-11-23T22:37:18.803611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(\"submission.csv\", \"w\")\n",
    "f.write(\"Id,Category\\n\")\n",
    "for (n,_),p in zip(test_loader.dataset.samples,preds):\n",
    "    f.write(\"{},{}\\n\".format(n.split('/')[-1].split('.')[0], int(p)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d11fe",
   "metadata": {
    "papermill": {
     "duration": 0.347159,
     "end_time": "2021-11-23T22:37:20.203554",
     "exception": false,
     "start_time": "2021-11-23T22:37:19.856395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1649.892727,
   "end_time": "2021-11-23T22:37:22.079833",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-23T22:09:52.187106",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "002ee9a798f341c8bc5fb2f11624f4e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2365b0a276d44ece97d45eb344d3e430": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3fc17e1f06034fdc8dec05696149ebeb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "436688b5bc284a97a149d86762f49ae7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "47eadc0afc6444cd8ee800f3bdf8fab7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4eaa3000170744d5ae05b0cc7605bbe6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "56154349e12e42229d4d6f7f5e6b2f50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57f255588fb547afa0ff895c3cff5472": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "594869fb022946408c098f2828e5df57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_857a38ad373946a3a86816872ffd69a3",
       "placeholder": "​",
       "style": "IPY_MODEL_436688b5bc284a97a149d86762f49ae7",
       "value": " 340M/340M [00:22&lt;00:00, 16.7MB/s]"
      }
     },
     "6005ac554e5e49faac1476799f094f0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c7969b3f1d6c426b959a11f1ab8d15d3",
        "IPY_MODEL_d88971a397c546568140c788f706cd06",
        "IPY_MODEL_594869fb022946408c098f2828e5df57"
       ],
       "layout": "IPY_MODEL_abb3a6513c99423381467eb9382554b3"
      }
     },
     "60b866b91e584d03bf6b177721cb1253": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_56154349e12e42229d4d6f7f5e6b2f50",
       "placeholder": "​",
       "style": "IPY_MODEL_4eaa3000170744d5ae05b0cc7605bbe6",
       "value": "100%"
      }
     },
     "7a65bb18dc5140cd969ef2a82647e345": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "857a38ad373946a3a86816872ffd69a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bc894f937fd4b17830758e7124b12a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abb3a6513c99423381467eb9382554b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b48dc1c1a13c45b59751e382d225eea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7a65bb18dc5140cd969ef2a82647e345",
       "placeholder": "​",
       "style": "IPY_MODEL_da637c8720674d389e5f890afbd3e18f",
       "value": " 170M/170M [00:11&lt;00:00, 16.8MB/s]"
      }
     },
     "c7969b3f1d6c426b959a11f1ab8d15d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9bc894f937fd4b17830758e7124b12a3",
       "placeholder": "​",
       "style": "IPY_MODEL_2365b0a276d44ece97d45eb344d3e430",
       "value": "100%"
      }
     },
     "d88971a397c546568140c788f706cd06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd01d55ec56246899a6bca6495351c8c",
       "max": 356082095.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3fc17e1f06034fdc8dec05696149ebeb",
       "value": 356082095.0
      }
     },
     "da637c8720674d389e5f890afbd3e18f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dcc00e54e6e24c369f3f5f58f9b803b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_60b866b91e584d03bf6b177721cb1253",
        "IPY_MODEL_e48ae40a1e9c413db09339cbe0fc1103",
        "IPY_MODEL_b48dc1c1a13c45b59751e382d225eea2"
       ],
       "layout": "IPY_MODEL_47eadc0afc6444cd8ee800f3bdf8fab7"
      }
     },
     "dd01d55ec56246899a6bca6495351c8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e48ae40a1e9c413db09339cbe0fc1103": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_002ee9a798f341c8bc5fb2f11624f4e2",
       "max": 178090079.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_57f255588fb547afa0ff895c3cff5472",
       "value": 178090079.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
